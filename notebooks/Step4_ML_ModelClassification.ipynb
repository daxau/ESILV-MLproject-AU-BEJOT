{
 "cells": [
  {
   "cell_type": "raw",
   "id": "db24864f-ff4f-42c9-bafd-cb780aa055da",
   "metadata": {},
   "source": [
    "# ===============================================================\n",
    "# MACHINE LEARNING PROJECT - 2025 GUIDELINES COMPLIANT\n",
    "# Title: Stock Price Direction Forecasting using Macroeconomic Indicators\n",
    "# Author: Dax AU / Téofil BEJOT\n",
    "# ===============================================================\n",
    "\n",
    "# Stock Price Direction Forecasting using Macroeconomic Indicators\n",
    "# -To predict whether a stock’s next-day return will be positive or negative, based on historical returns and macro-economic variables.\n",
    "\n",
    "# Predicting Apple Stock Direction — Full ML Pipeline\n",
    "# This notebook covers these sequential steps:\n",
    "5) Train/test split\n",
    "6) Train models\n",
    "7) Hyperparameter tuning\n",
    "8) Evaluate metrics & compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0694cd-7df9-4cab-950a-a305dc9b4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 1) IMPORT LIBRARIES\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e939bfd-5e2f-4da7-b5ca-4fac503faaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 1) LOAD DATASETS\n",
    "# ===============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "OUT = Path(\"../data\")\n",
    "print(OUT)\n",
    "\n",
    "data = pd.read_csv(OUT / 'Cleaned_Features_for_ML.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "DATASET_LABEL = \"Cleaned_Features_for_ML\"   # or \"Cleaned_Features_for_ML_20ANOVA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561f1b4d-fa83-4c62-a5f0-9ef943ec8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4085 entries, 2010-03-15 to 2025-11-26\n",
      "Data columns (total 44 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   S&P500                             4085 non-null   float64\n",
      " 1   NASDAQ                             4085 non-null   float64\n",
      " 2   DowJones                           4085 non-null   float64\n",
      " 3   CAC40                              4085 non-null   float64\n",
      " 4   DAX                                4085 non-null   float64\n",
      " 5   FTSE100                            4085 non-null   float64\n",
      " 6   Nikkei225                          4085 non-null   float64\n",
      " 7   HangSeng                           4085 non-null   float64\n",
      " 8   MSCIWorld                          4085 non-null   float64\n",
      " 9   US10Y                              4085 non-null   float64\n",
      " 10  US2Y                               4085 non-null   float64\n",
      " 11  TLT                                4085 non-null   float64\n",
      " 12  IEF                                4085 non-null   float64\n",
      " 13  BND                                4085 non-null   float64\n",
      " 14  LQD                                4085 non-null   float64\n",
      " 15  Apple                              4085 non-null   float64\n",
      " 16  Microsoft                          4085 non-null   float64\n",
      " 17  Google                             4085 non-null   float64\n",
      " 18  Amazon                             4085 non-null   float64\n",
      " 19  Meta                               4085 non-null   float64\n",
      " 20  Inflation_CPI                      4085 non-null   float64\n",
      " 21  Unemployment_Rate                  4085 non-null   float64\n",
      " 22  Fed_Funds_Rate                     4085 non-null   float64\n",
      " 23  Real_GDP                           4085 non-null   float64\n",
      " 24  Yield_Curve_Spread                 4085 non-null   float64\n",
      " 25  Industrial_Production              4085 non-null   float64\n",
      " 26  M2_Money_Supply                    4085 non-null   float64\n",
      " 27  Personal_Consumption_Expenditures  4085 non-null   float64\n",
      " 28  Recession_Probability              4085 non-null   float64\n",
      " 29  GDP_Current_USD                    4085 non-null   float64\n",
      " 30  Inflation_Annual_Pct               4085 non-null   float64\n",
      " 31  Unemployment_Total_Pct             4085 non-null   float64\n",
      " 32  Exports_GDP_Pct                    4085 non-null   float64\n",
      " 33  Imports_GDP_Pct                    4085 non-null   float64\n",
      " 34  Public_Debt_GDP_Pct                4085 non-null   float64\n",
      " 35  OECD_CPI_2015idx_USA               4085 non-null   float64\n",
      " 36  OECD_Unemp_rate_pct_USA            4085 non-null   float64\n",
      " 37  Return                             4085 non-null   float64\n",
      " 38  Volatility_20d                     4085 non-null   float64\n",
      " 39  MA20                               4085 non-null   float64\n",
      " 40  MA50                               4085 non-null   float64\n",
      " 41  Momentum                           4085 non-null   float64\n",
      " 42  RSI                                4085 non-null   float64\n",
      " 43  Direction                          4085 non-null   int64  \n",
      "dtypes: float64(43), int64(1)\n",
      "memory usage: 1.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94092243-a0c8-4658-abe8-90e166f6739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#  SAVE RESULTS HELPERS (JSON + CSV EXPORT)\n",
    "# ===============================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================================\n",
    "# Define output folder inside project: /data\n",
    "# ===============================================================\n",
    "\n",
    "OUT = Path(\"../data\")   # <-- for notebooks located inside /notebooks/\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_json_serializable(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert objects (numpy arrays, numpy numbers, dicts, lists)\n",
    "    into JSON-serializable Python native types.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# ===============================================================\n",
    "# JSON + CSV Saving Utilities\n",
    "# ===============================================================\n",
    "\n",
    "def save_results_to_json(results_dict, filename=\"model_results.json\"):\n",
    "    \"\"\"Save the entire results dictionary into /data as JSON.\"\"\"\n",
    "    results_serializable = make_json_serializable(results_dict)\n",
    "    filepath = OUT / filename\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(results_serializable, f, indent=4)\n",
    "\n",
    "    print(f\"[INFO] Saved JSON to: {filepath.resolve()}\")\n",
    "\n",
    "\n",
    "def save_results_to_csv(results_dict, filename=\"model_results.csv\"):\n",
    "    \"\"\"Flatten model metrics into tabular CSV saved under /data.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for model_name, res in results_dict.items():\n",
    "        cm = np.array(res.get(\"confusion_matrix\"))\n",
    "        cr = res.get(\"classification_report\", {})\n",
    "        roc_auc = res.get(\"roc_auc\", None)\n",
    "        f2 = res.get(\"f2_score\", None)\n",
    "        comp_time = res.get(\"computation_time_sec\", None)\n",
    "\n",
    "        # Accuracy\n",
    "        acc = cr.get(\"accuracy\", None)\n",
    "\n",
    "        # Positive class key\n",
    "        pos_key = \"1\" if \"1\" in cr else None\n",
    "        if not pos_key:\n",
    "            keys = [k for k in cr.keys() if k.isdigit()]\n",
    "            if keys:\n",
    "                pos_key = keys[-1]\n",
    "\n",
    "        precision_1 = recall_1 = f1_1 = None\n",
    "        if pos_key and isinstance(cr.get(pos_key), dict):\n",
    "            precision_1 = cr[pos_key].get(\"precision\")\n",
    "            recall_1 = cr[pos_key].get(\"recall\")\n",
    "            f1_1 = cr[pos_key].get(\"f1-score\")\n",
    "\n",
    "        # Confusion matrix extract\n",
    "        tn = fp = fn = tp = None\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        rows.append({\n",
    "            \"Dataset\": res.get(\"dataset_label\", \"Unknown\"),   # <--- added\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision (class 1)\": precision_1,\n",
    "            \"Recall (class 1)\": recall_1,\n",
    "            \"F1-score (class 1)\": f1_1,\n",
    "            \"F2-score\": f2,\n",
    "            \"ROC-AUC\": roc_auc,\n",
    "            \"Computation Time (sec)\": comp_time,\n",
    "            \"TN\": tn,\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn,\n",
    "            \"TP\": tp,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    filepath = OUT / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"[INFO] Saved CSV to: {filepath.resolve()}\")\n",
    "\n",
    "\n",
    "# GLOBAL CONTAINER\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd19b10-d0ee-4707-b895-64a0b7aaa8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_name, y_true, y_pred, y_prob=None, comp_time=None):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, fbeta_score\n",
    "\n",
    "    # Create entry\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    results[model_name][\"confusion_matrix\"] = cm\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    results[model_name][\"classification_report\"] = report\n",
    "\n",
    "    # ROC-AUC\n",
    "    if y_prob is not None:\n",
    "        results[model_name][\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    # F2-score\n",
    "    results[model_name][\"f2_score\"] = fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "    # Computation time\n",
    "    results[model_name][\"computation_time_sec\"] = comp_time\n",
    "\n",
    "    print(f\"✓ Saved model results for: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd644ec-a012-4f15-b13c-74f98e40e406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3268, 41) | Test shape: (817, 41)\n",
      "Numeric features: 41 | Categorical features: 0\n",
      "\n",
      "====================================================\n",
      " RUNNING MODELS — CLEAN OUTPUT TABLE FORMAT \n",
      "====================================================\n",
      "\n",
      "\n",
      "▶ Training LR ...\n",
      "   ACC=0.5288 | F1=0.6419 | AUC=0.5115 | F2=0.7322 | Time=0.23 sec\n",
      "\n",
      "▶ Training KNN ...\n",
      "   ACC=0.4908 | F1=0.5218 | AUC=0.5018 | F2=0.5277 | Time=0.41 sec\n",
      "\n",
      "▶ Training CART ...\n",
      "   ACC=0.4859 | F1=0.4750 | AUC=0.4936 | F2=0.4565 | Time=0.09 sec\n",
      "\n",
      "▶ Training SVC ...\n",
      "   ACC=0.5239 | F1=0.6860 | AUC=0.4910 | F2=0.8433 | Time=3.09 sec\n",
      "\n",
      "▶ Training MLP ...\n",
      "   ACC=0.4798 | F1=0.2230 | AUC=0.5015 | F2=0.1668 | Time=3.45 sec\n",
      "\n",
      "▶ Training ABR ...\n",
      "   ACC=0.4908 | F1=0.5922 | AUC=0.4897 | F2=0.6562 | Time=3.94 sec\n",
      "\n",
      "▶ Training GBR ...\n",
      "   ACC=0.5202 | F1=0.6364 | AUC=0.5117 | F2=0.7270 | Time=8.56 sec\n",
      "\n",
      "▶ Training RFR ...\n",
      "   ACC=0.4945 | F1=0.5447 | AUC=0.4913 | F2=0.5644 | Time=4.48 sec\n",
      "\n",
      "▶ Training ETR ...\n",
      "   ACC=0.5141 | F1=0.5834 | AUC=0.5262 | F2=0.6222 | Time=1.60 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c623_row0_col1 {\n",
       "  background-color: #2e7ebc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row0_col2 {\n",
       "  background-color: #1b69af;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row0_col3, #T_6c623_row1_col5, #T_6c623_row2_col1, #T_6c623_row7_col2, #T_6c623_row7_col4 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row0_col4 {\n",
       "  background-color: #3585bf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row0_col5 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row1_col1 {\n",
       "  background-color: #125da6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row1_col2 {\n",
       "  background-color: #084c95;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row1_col3 {\n",
       "  background-color: #4997c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row1_col4 {\n",
       "  background-color: #115ca5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row2_col2 {\n",
       "  background-color: #084990;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row2_col3 {\n",
       "  background-color: #4b98ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row2_col4 {\n",
       "  background-color: #105ba4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row2_col5 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row3_col1, #T_6c623_row8_col1 {\n",
       "  background-color: #cbdef1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row3_col2 {\n",
       "  background-color: #3c8cc3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row3_col3 {\n",
       "  background-color: #add0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row3_col4 {\n",
       "  background-color: #60a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row3_col5, #T_6c623_row7_col3 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row4_col1, #T_6c623_row4_col2, #T_6c623_row4_col4, #T_6c623_row5_col5, #T_6c623_row8_col3 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row4_col3 {\n",
       "  background-color: #afd1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row4_col5 {\n",
       "  background-color: #95c5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row5_col1 {\n",
       "  background-color: #deebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row5_col2 {\n",
       "  background-color: #5ca4d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row5_col3 {\n",
       "  background-color: #e3eef8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row5_col4 {\n",
       "  background-color: #89bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row6_col1 {\n",
       "  background-color: #b7d4ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row6_col2 {\n",
       "  background-color: #3080bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row6_col3 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row6_col4 {\n",
       "  background-color: #4e9acb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row6_col5 {\n",
       "  background-color: #65aad4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row7_col1 {\n",
       "  background-color: #084a91;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row7_col5 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6c623_row8_col2 {\n",
       "  background-color: #1764ab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row8_col4 {\n",
       "  background-color: #2777b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c623_row8_col5 {\n",
       "  background-color: #7db8da;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c623\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6c623_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6c623_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6c623_level0_col2\" class=\"col_heading level0 col2\" >F1-score</th>\n",
       "      <th id=\"T_6c623_level0_col3\" class=\"col_heading level0 col3\" >AUC</th>\n",
       "      <th id=\"T_6c623_level0_col4\" class=\"col_heading level0 col4\" >F2-score</th>\n",
       "      <th id=\"T_6c623_level0_col5\" class=\"col_heading level0 col5\" >Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c623_row0_col0\" class=\"data row0 col0\" >ETR</td>\n",
       "      <td id=\"T_6c623_row0_col1\" class=\"data row0 col1\" >0.514076</td>\n",
       "      <td id=\"T_6c623_row0_col2\" class=\"data row0 col2\" >0.583421</td>\n",
       "      <td id=\"T_6c623_row0_col3\" class=\"data row0 col3\" >0.526196</td>\n",
       "      <td id=\"T_6c623_row0_col4\" class=\"data row0 col4\" >0.622202</td>\n",
       "      <td id=\"T_6c623_row0_col5\" class=\"data row0 col5\" >1.596354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6c623_row1_col0\" class=\"data row1 col0\" >GBR</td>\n",
       "      <td id=\"T_6c623_row1_col1\" class=\"data row1 col1\" >0.520196</td>\n",
       "      <td id=\"T_6c623_row1_col2\" class=\"data row1 col2\" >0.636364</td>\n",
       "      <td id=\"T_6c623_row1_col3\" class=\"data row1 col3\" >0.511692</td>\n",
       "      <td id=\"T_6c623_row1_col4\" class=\"data row1 col4\" >0.727003</td>\n",
       "      <td id=\"T_6c623_row1_col5\" class=\"data row1 col5\" >8.562033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6c623_row2_col0\" class=\"data row2 col0\" >LR</td>\n",
       "      <td id=\"T_6c623_row2_col1\" class=\"data row2 col1\" >0.528764</td>\n",
       "      <td id=\"T_6c623_row2_col2\" class=\"data row2 col2\" >0.641860</td>\n",
       "      <td id=\"T_6c623_row2_col3\" class=\"data row2 col3\" >0.511487</td>\n",
       "      <td id=\"T_6c623_row2_col4\" class=\"data row2 col4\" >0.732173</td>\n",
       "      <td id=\"T_6c623_row2_col5\" class=\"data row2 col5\" >0.225107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6c623_row3_col0\" class=\"data row3 col0\" >KNN</td>\n",
       "      <td id=\"T_6c623_row3_col1\" class=\"data row3 col1\" >0.490820</td>\n",
       "      <td id=\"T_6c623_row3_col2\" class=\"data row3 col2\" >0.521839</td>\n",
       "      <td id=\"T_6c623_row3_col3\" class=\"data row3 col3\" >0.501768</td>\n",
       "      <td id=\"T_6c623_row3_col4\" class=\"data row3 col4\" >0.527662</td>\n",
       "      <td id=\"T_6c623_row3_col5\" class=\"data row3 col5\" >0.413375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6c623_row4_col0\" class=\"data row4 col0\" >MLP</td>\n",
       "      <td id=\"T_6c623_row4_col1\" class=\"data row4 col1\" >0.479804</td>\n",
       "      <td id=\"T_6c623_row4_col2\" class=\"data row4 col2\" >0.223035</td>\n",
       "      <td id=\"T_6c623_row4_col3\" class=\"data row4 col3\" >0.501543</td>\n",
       "      <td id=\"T_6c623_row4_col4\" class=\"data row4 col4\" >0.166849</td>\n",
       "      <td id=\"T_6c623_row4_col5\" class=\"data row4 col5\" >3.453799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6c623_row5_col0\" class=\"data row5 col0\" >CART</td>\n",
       "      <td id=\"T_6c623_row5_col1\" class=\"data row5 col1\" >0.485924</td>\n",
       "      <td id=\"T_6c623_row5_col2\" class=\"data row5 col2\" >0.475000</td>\n",
       "      <td id=\"T_6c623_row5_col3\" class=\"data row5 col3\" >0.493578</td>\n",
       "      <td id=\"T_6c623_row5_col4\" class=\"data row5 col4\" >0.456511</td>\n",
       "      <td id=\"T_6c623_row5_col5\" class=\"data row5 col5\" >0.087076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6c623_row6_col0\" class=\"data row6 col0\" >RFR</td>\n",
       "      <td id=\"T_6c623_row6_col1\" class=\"data row6 col1\" >0.494492</td>\n",
       "      <td id=\"T_6c623_row6_col2\" class=\"data row6 col2\" >0.544653</td>\n",
       "      <td id=\"T_6c623_row6_col3\" class=\"data row6 col3\" >0.491314</td>\n",
       "      <td id=\"T_6c623_row6_col4\" class=\"data row6 col4\" >0.564442</td>\n",
       "      <td id=\"T_6c623_row6_col5\" class=\"data row6 col5\" >4.476214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6c623_row7_col0\" class=\"data row7 col0\" >SVC</td>\n",
       "      <td id=\"T_6c623_row7_col1\" class=\"data row7 col1\" >0.523868</td>\n",
       "      <td id=\"T_6c623_row7_col2\" class=\"data row7 col2\" >0.686037</td>\n",
       "      <td id=\"T_6c623_row7_col3\" class=\"data row7 col3\" >0.491035</td>\n",
       "      <td id=\"T_6c623_row7_col4\" class=\"data row7 col4\" >0.843254</td>\n",
       "      <td id=\"T_6c623_row7_col5\" class=\"data row7 col5\" >3.091851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c623_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6c623_row8_col0\" class=\"data row8 col0\" >ABR</td>\n",
       "      <td id=\"T_6c623_row8_col1\" class=\"data row8 col1\" >0.490820</td>\n",
       "      <td id=\"T_6c623_row8_col2\" class=\"data row8 col2\" >0.592157</td>\n",
       "      <td id=\"T_6c623_row8_col3\" class=\"data row8 col3\" >0.489750</td>\n",
       "      <td id=\"T_6c623_row8_col4\" class=\"data row8 col4\" >0.656236</td>\n",
       "      <td id=\"T_6c623_row8_col5\" class=\"data row8 col5\" >3.938603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29dbec42f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# BINARY CLASSIFICATION – K-FOLD EVALUATION (FULL PIPELINE)\n",
    "# ===============================================================\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) IMPORTS\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, GradientBoostingClassifier,\n",
    "    RandomForestClassifier, ExtraTreesClassifier\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# 2) TRAIN / TEST SPLIT\n",
    "# ===============================================================\n",
    "features = data.drop(columns=['Apple', 'Return', 'Direction'])\n",
    "target = data[\"Direction\"] \n",
    "\n",
    "# Handle infinities and missing values early\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, shuffle=False\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape} | Test shape: {X_test.shape}\")\n",
    "\n",
    "# ===============================================================\n",
    "# 3) FEATURE TYPES\n",
    "# ===============================================================\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)} | Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# ===============================================================\n",
    "# 4) PREPROCESSING PIPELINES\n",
    "# ===============================================================\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# ===============================================================\n",
    "# 5) DEFINE MODELS\n",
    "# ===============================================================\n",
    "models = [\n",
    "    ('LR',  LogisticRegression(max_iter=5000, random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('CART', DecisionTreeClassifier(max_depth=6, random_state=42)),\n",
    "    ('SVC', SVC(kernel='rbf', probability=True, random_state=42)),\n",
    "    ('MLP', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=5000, random_state=42)),\n",
    "    # Boosting\n",
    "    ('ABR', AdaBoostClassifier(n_estimators=300, random_state=42)),\n",
    "    ('GBR', GradientBoostingClassifier(n_estimators=300, random_state=42)),\n",
    "    # Bagging\n",
    "    ('RFR', RandomForestClassifier(n_estimators=300, random_state=42)),\n",
    "    ('ETR', ExtraTreesClassifier(n_estimators=300, random_state=42))\n",
    "]\n",
    "\n",
    "# ===============================================================\n",
    "# BINARY CLASSIFICATION — MODEL EVALUATION (Production Format)\n",
    "# Output Table = [Model | Accuracy | F1 | AUC | F2 | Time]\n",
    "# ===============================================================\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, fbeta_score\n",
    ")\n",
    "\n",
    "results = {}    # global container for JSON/CSV export\n",
    "rows_for_display = []   # container for final table display\n",
    "\n",
    "print(\"\\n====================================================\")\n",
    "print(\" RUNNING MODELS — CLEAN OUTPUT TABLE FORMAT \")\n",
    "print(\"====================================================\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    print(f\"\\n▶ Training {name} ...\")\n",
    "\n",
    "    # Build final pipeline\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "\n",
    "    # ---- Start Timer ----\n",
    "    t0 = time()\n",
    "\n",
    "    # Fit model\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Probabilities for AUC\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = np.zeros_like(y_pred)\n",
    "\n",
    "    # ---- Compute Metrics ----\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred)\n",
    "    f2  = fbeta_score(y_test, y_pred, beta=2)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    comp_time = time() - t0\n",
    "\n",
    "    # Confusion matrix + full report\n",
    "    cm     = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # ---- Save to global results dict (for Streamlit + JSON/CSV) ----\n",
    "    results[name] = {\n",
    "        \"dataset_label\": DATASET_LABEL,     # <--- added\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f2_score\": float(f2),\n",
    "        \"computation_time_sec\": float(comp_time),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "    # ---- Save row for final output table ----\n",
    "    rows_for_display.append([\n",
    "        name, acc, f1, auc, f2, comp_time\n",
    "    ])\n",
    "\n",
    "    print(f\"   ACC={acc:.4f} | F1={f1:.4f} | AUC={auc:.4f} | F2={f2:.4f} | Time={comp_time:.2f} sec\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# FINAL SUMMARY TABLE (Matches your screenshot format!)\n",
    "# ===============================================================\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    rows_for_display,\n",
    "    columns=[\"Model\", \"Accuracy\", \"F1-score\", \"AUC\", \"F2-score\", \"Time (sec)\"]\n",
    ")\n",
    "\n",
    "# Sort by AUC descending (or F1 if you prefer)\n",
    "df_results = df_results.sort_values(\"AUC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(df_results.style.background_gradient(cmap=\"Blues\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af28ab9c-c1d1-43f6-a096-39287cfe48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved JSON to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.json\n",
      "[INFO] Saved CSV to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.csv\n",
      "✓ All results exported successfully.\n"
     ]
    }
   ],
   "source": [
    "save_results_to_json(results, \"model_results.json\")\n",
    "save_results_to_csv(results, \"model_results.csv\")\n",
    "print(\"✓ All results exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13755411-0852-47b3-b1ed-2289d1a82d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================\n",
      "   ADVANCED ML MODELS – ENSEMBLE & STACKING\n",
      "====================================================\n",
      "\n",
      "\n",
      "▶ Training Tuned SVM ...\n",
      "\n",
      "Tuned SVM:\n",
      "  ACC  = 0.5226\n",
      "  F1   = 0.6865\n",
      "  F2   = 0.8455\n",
      "  AUC  = 0.4877\n",
      "  Time = 3.51 sec\n",
      "\n",
      "\n",
      "▶ Training Tuned Decision Tree ...\n",
      "\n",
      "Tuned Decision Tree:\n",
      "  ACC  = 0.4982\n",
      "  F1   = 0.5747\n",
      "  F2   = 0.6169\n",
      "  AUC  = 0.5093\n",
      "  Time = 0.10 sec\n",
      "\n",
      "\n",
      "▶ Training Bagging SVM ...\n",
      "\n",
      "Bagging SVM:\n",
      "  ACC  = 0.5226\n",
      "  F1   = 0.6865\n",
      "  F2   = 0.8455\n",
      "  AUC  = 0.4881\n",
      "  Time = 20.03 sec\n",
      "\n",
      "\n",
      "▶ Training Bagging Decision Tree ...\n",
      "\n",
      "Bagging Decision Tree:\n",
      "  ACC  = 0.4725\n",
      "  F1   = 0.4712\n",
      "  F2   = 0.4580\n",
      "  AUC  = 0.4725\n",
      "  Time = 3.52 sec\n",
      "\n",
      "\n",
      "▶ Training Voting (SVM + DT) ...\n",
      "\n",
      "Voting (SVM + DT):\n",
      "  ACC  = 0.5080\n",
      "  F1   = 0.5000\n",
      "  F2   = 0.4820\n",
      "  AUC  = 0.5024\n",
      "  Time = 3.14 sec\n",
      "\n",
      "\n",
      "▶ Training Stacking Meta-Model ...\n",
      "\n",
      "Stacking Meta-Model:\n",
      "  ACC  = 0.5239\n",
      "  F1   = 0.6299\n",
      "  F2   = 0.7097\n",
      "  AUC  = 0.5121\n",
      "  Time = 23.48 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c9865_row0_col1, #T_c9865_row0_col3, #T_c9865_row0_col5, #T_c9865_row3_col2, #T_c9865_row3_col4, #T_c9865_row4_col2, #T_c9865_row4_col4 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row0_col2 {\n",
       "  background-color: #2474b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row0_col4 {\n",
       "  background-color: #3b8bc2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row1_col1 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row1_col2 {\n",
       "  background-color: #72b2d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row1_col3 {\n",
       "  background-color: #084387;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row1_col4 {\n",
       "  background-color: #91c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row1_col5, #T_c9865_row5_col1, #T_c9865_row5_col2, #T_c9865_row5_col3, #T_c9865_row5_col4 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row2_col1 {\n",
       "  background-color: #3181bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row2_col2 {\n",
       "  background-color: #dceaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row2_col3 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row2_col4 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row2_col5 {\n",
       "  background-color: #ddeaf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row3_col1, #T_c9865_row4_col1 {\n",
       "  background-color: #083674;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row3_col3 {\n",
       "  background-color: #97c6df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row3_col5 {\n",
       "  background-color: #0c56a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c9865_row4_col3 {\n",
       "  background-color: #9cc9e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c9865_row4_col5, #T_c9865_row5_col5 {\n",
       "  background-color: #dae8f6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c9865\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c9865_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c9865_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_c9865_level0_col2\" class=\"col_heading level0 col2\" >F1-score</th>\n",
       "      <th id=\"T_c9865_level0_col3\" class=\"col_heading level0 col3\" >AUC</th>\n",
       "      <th id=\"T_c9865_level0_col4\" class=\"col_heading level0 col4\" >F2-score</th>\n",
       "      <th id=\"T_c9865_level0_col5\" class=\"col_heading level0 col5\" >Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c9865_row0_col0\" class=\"data row0 col0\" >Stacking Meta-Model</td>\n",
       "      <td id=\"T_c9865_row0_col1\" class=\"data row0 col1\" >0.523868</td>\n",
       "      <td id=\"T_c9865_row0_col2\" class=\"data row0 col2\" >0.629876</td>\n",
       "      <td id=\"T_c9865_row0_col3\" class=\"data row0 col3\" >0.512136</td>\n",
       "      <td id=\"T_c9865_row0_col4\" class=\"data row0 col4\" >0.709691</td>\n",
       "      <td id=\"T_c9865_row0_col5\" class=\"data row0 col5\" >23.475039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c9865_row1_col0\" class=\"data row1 col0\" >Tuned Decision Tree</td>\n",
       "      <td id=\"T_c9865_row1_col1\" class=\"data row1 col1\" >0.498164</td>\n",
       "      <td id=\"T_c9865_row1_col2\" class=\"data row1 col2\" >0.574689</td>\n",
       "      <td id=\"T_c9865_row1_col3\" class=\"data row1 col3\" >0.509347</td>\n",
       "      <td id=\"T_c9865_row1_col4\" class=\"data row1 col4\" >0.616927</td>\n",
       "      <td id=\"T_c9865_row1_col5\" class=\"data row1 col5\" >0.095397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c9865_row2_col0\" class=\"data row2 col0\" >Voting (SVM + DT)</td>\n",
       "      <td id=\"T_c9865_row2_col1\" class=\"data row2 col1\" >0.507956</td>\n",
       "      <td id=\"T_c9865_row2_col2\" class=\"data row2 col2\" >0.500000</td>\n",
       "      <td id=\"T_c9865_row2_col3\" class=\"data row2 col3\" >0.502384</td>\n",
       "      <td id=\"T_c9865_row2_col4\" class=\"data row2 col4\" >0.482014</td>\n",
       "      <td id=\"T_c9865_row2_col5\" class=\"data row2 col5\" >3.142823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c9865_row3_col0\" class=\"data row3 col0\" >Bagging SVM</td>\n",
       "      <td id=\"T_c9865_row3_col1\" class=\"data row3 col1\" >0.522644</td>\n",
       "      <td id=\"T_c9865_row3_col2\" class=\"data row3 col2\" >0.686495</td>\n",
       "      <td id=\"T_c9865_row3_col3\" class=\"data row3 col3\" >0.488116</td>\n",
       "      <td id=\"T_c9865_row3_col4\" class=\"data row3 col4\" >0.845545</td>\n",
       "      <td id=\"T_c9865_row3_col5\" class=\"data row3 col5\" >20.029305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c9865_row4_col0\" class=\"data row4 col0\" >Tuned SVM</td>\n",
       "      <td id=\"T_c9865_row4_col1\" class=\"data row4 col1\" >0.522644</td>\n",
       "      <td id=\"T_c9865_row4_col2\" class=\"data row4 col2\" >0.686495</td>\n",
       "      <td id=\"T_c9865_row4_col3\" class=\"data row4 col3\" >0.487666</td>\n",
       "      <td id=\"T_c9865_row4_col4\" class=\"data row4 col4\" >0.845545</td>\n",
       "      <td id=\"T_c9865_row4_col5\" class=\"data row4 col5\" >3.506093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9865_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c9865_row5_col0\" class=\"data row5 col0\" >Bagging Decision Tree</td>\n",
       "      <td id=\"T_c9865_row5_col1\" class=\"data row5 col1\" >0.472460</td>\n",
       "      <td id=\"T_c9865_row5_col2\" class=\"data row5 col2\" >0.471166</td>\n",
       "      <td id=\"T_c9865_row5_col3\" class=\"data row5 col3\" >0.472539</td>\n",
       "      <td id=\"T_c9865_row5_col4\" class=\"data row5 col4\" >0.458015</td>\n",
       "      <td id=\"T_c9865_row5_col5\" class=\"data row5 col5\" >3.523920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29dbec43a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# ADVANCED MODELS – ENSEMBLE & META-LEARNING COMPARISON\n",
    "# ===============================================================\n",
    "print(\"\\n====================================================\")\n",
    "print(\"   ADVANCED ML MODELS – ENSEMBLE & STACKING\")\n",
    "print(\"====================================================\\n\")\n",
    "\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    fbeta_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# 1) PREPROCESSING PIPELINE\n",
    "# ===============================================================\n",
    "def make_pipeline(model):\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "# Base models\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "base_dt  = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 2) TUNED MODELS WITH GRID SEARCH\n",
    "# ===============================================================\n",
    "\n",
    "# --- SVM ---\n",
    "param_svm = {\n",
    "    \"model__C\": [0.1, 1, 10],\n",
    "    \"model__gamma\": [\"scale\", 0.01, 0.001]\n",
    "}\n",
    "\n",
    "tuned_svm = GridSearchCV(\n",
    "    make_pipeline(SVC(probability=True, random_state=0)),\n",
    "    param_svm,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "tuned_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- Decision Tree ---\n",
    "param_dt = {\n",
    "    \"model__max_depth\": [3, 5, 7, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "tuned_dt = GridSearchCV(\n",
    "    make_pipeline(DecisionTreeClassifier(random_state=0)),\n",
    "    param_dt,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "tuned_dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3) BAGGING MODELS\n",
    "# ===============================================================\n",
    "\n",
    "bagging_svm = make_pipeline(\n",
    "    BaggingClassifier(\n",
    "        estimator=SVC(kernel='rbf', probability=True),\n",
    "        n_estimators=20,\n",
    "        max_samples=0.8,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "bagging_dt = make_pipeline(\n",
    "    BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 4) VOTING CLASSIFIER\n",
    "# ===============================================================\n",
    "voting = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', SVC(kernel='rbf', probability=True)),\n",
    "            ('dt', DecisionTreeClassifier())\n",
    "        ],\n",
    "        voting='soft'\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 5) STACKING CLASSIFIER\n",
    "# ===============================================================\n",
    "stacking = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", StackingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', SVC(kernel='rbf', probability=True)),\n",
    "            ('dt', DecisionTreeClassifier()),\n",
    "            ('bag_svm', BaggingClassifier(\n",
    "                estimator=SVC(kernel='rbf', probability=True),\n",
    "                n_estimators=10)),\n",
    "            ('bag_dt', BaggingClassifier(\n",
    "                estimator=DecisionTreeClassifier(),\n",
    "                n_estimators=10))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(max_iter=500),\n",
    "        passthrough=True,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 6) MODEL COLLECTION\n",
    "# ===============================================================\n",
    "ensemble_models = {\n",
    "    \"Tuned SVM\": tuned_svm.best_estimator_,\n",
    "    \"Tuned Decision Tree\": tuned_dt.best_estimator_,\n",
    "    \"Bagging SVM\": bagging_svm,\n",
    "    \"Bagging Decision Tree\": bagging_dt,\n",
    "    \"Voting (SVM + DT)\": voting,\n",
    "    \"Stacking Meta-Model\": stacking\n",
    "}\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 7) MASTER LOOP — TRAIN + EVALUATE + LOG INTO RESULTS\n",
    "# ===============================================================\n",
    "for name, model in ensemble_models.items():\n",
    "\n",
    "    print(f\"\\n▶ Training {name} ...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = np.zeros_like(y_pred)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred)\n",
    "    f2  = fbeta_score(y_test, y_pred, beta=2)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    comp_time = time.time() - start_time\n",
    "\n",
    "    # SAVE to global results dict — identical to your classic models structure\n",
    "    results[name] = {\n",
    "        \"dataset_label\": DATASET_LABEL,     # <--- added\n",
    "        \"train_accuracy\": None,       # optional for ensembles\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f2_score\": float(f2),\n",
    "        \"computation_time_sec\": float(comp_time),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "    print(f\"\"\"\n",
    "{name}:\n",
    "  ACC  = {acc:.4f}\n",
    "  F1   = {f1:.4f}\n",
    "  F2   = {f2:.4f}\n",
    "  AUC  = {auc:.4f}\n",
    "  Time = {comp_time:.2f} sec\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 8) SUMMARY TABLE FOR DISPLAY — Ranked & Colored (as screenshot)\n",
    "# ===============================================================\n",
    "\n",
    "df_results_ens = pd.DataFrame([\n",
    "    [\n",
    "        name,\n",
    "        results[name][\"test_accuracy\"],\n",
    "        results[name][\"f1_score\"],\n",
    "        results[name][\"roc_auc\"],\n",
    "        results[name][\"f2_score\"],\n",
    "        results[name][\"computation_time_sec\"]\n",
    "    ]\n",
    "    for name in ensemble_models.keys()\n",
    "], columns=[\"Model\", \"Accuracy\", \"F1-score\", \"AUC\", \"F2-score\", \"Time (sec)\"])\n",
    "\n",
    "# ---- SORT by AUC (or switch to F1-score if preferred) ----\n",
    "df_results_ens = df_results_ens.sort_values(by=\"AUC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---- DISPLAY WITH BLUE GRADIENT BACKGROUND ----\n",
    "display(\n",
    "    df_results_ens.style.background_gradient(\n",
    "        cmap=\"Blues\",\n",
    "        subset=[\"Accuracy\", \"F1-score\", \"AUC\", \"F2-score\", \"Time (sec)\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb3ce38e-3fd5-467d-9edd-13d2a228889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved JSON to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.json\n",
      "[INFO] Saved CSV to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.csv\n",
      "✓ All results exported successfully.\n"
     ]
    }
   ],
   "source": [
    "save_results_to_json(results, \"model_results.json\")\n",
    "save_results_to_csv(results, \"model_results.csv\")\n",
    "print(\"✓ All results exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0575e7-7f29-4a78-a370-063a21455c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
