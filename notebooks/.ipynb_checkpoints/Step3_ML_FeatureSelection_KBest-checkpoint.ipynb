{
 "cells": [
  {
   "cell_type": "raw",
   "id": "db24864f-ff4f-42c9-bafd-cb780aa055da",
   "metadata": {},
   "source": [
    "# ===============================================================\n",
    "# MACHINE LEARNING PROJECT - 2025 GUIDELINES COMPLIANT\n",
    "# Title: Stock Price Direction Forecasting using Macroeconomic Indicators\n",
    "# Author: Dax AU & Teofil BEJOT\n",
    "# ===============================================================\n",
    "\n",
    "# Stock Price Direction Forecasting using Macroeconomic Indicators\n",
    "# -To predict whether a stock’s next-day return will be positive or negative, based on historical returns and macro-economic variables.\n",
    "\n",
    "# Predicting Apple Stock Direction — Full ML Pipeline\n",
    "# This notebook covers this single step:\n",
    "4) Dataset reduction and features selection - based on ANOVA filter method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0694cd-7df9-4cab-950a-a305dc9b4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 1) IMPORT LIBRARIES\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e939bfd-5e2f-4da7-b5ca-4fac503faaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 1) LOAD DATASETS\n",
    "# ===============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "OUT = Path(\"../data\")\n",
    "print(OUT)\n",
    "\n",
    "data = pd.read_csv(OUT / 'Cleaned_Features_for_ML.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561f1b4d-fa83-4c62-a5f0-9ef943ec8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4085 entries, 2010-03-15 to 2025-11-26\n",
      "Data columns (total 44 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   S&P500                             4085 non-null   float64\n",
      " 1   NASDAQ                             4085 non-null   float64\n",
      " 2   DowJones                           4085 non-null   float64\n",
      " 3   CAC40                              4085 non-null   float64\n",
      " 4   DAX                                4085 non-null   float64\n",
      " 5   FTSE100                            4085 non-null   float64\n",
      " 6   Nikkei225                          4085 non-null   float64\n",
      " 7   HangSeng                           4085 non-null   float64\n",
      " 8   MSCIWorld                          4085 non-null   float64\n",
      " 9   US10Y                              4085 non-null   float64\n",
      " 10  US2Y                               4085 non-null   float64\n",
      " 11  TLT                                4085 non-null   float64\n",
      " 12  IEF                                4085 non-null   float64\n",
      " 13  BND                                4085 non-null   float64\n",
      " 14  LQD                                4085 non-null   float64\n",
      " 15  Apple                              4085 non-null   float64\n",
      " 16  Microsoft                          4085 non-null   float64\n",
      " 17  Google                             4085 non-null   float64\n",
      " 18  Amazon                             4085 non-null   float64\n",
      " 19  Meta                               4085 non-null   float64\n",
      " 20  Inflation_CPI                      4085 non-null   float64\n",
      " 21  Unemployment_Rate                  4085 non-null   float64\n",
      " 22  Fed_Funds_Rate                     4085 non-null   float64\n",
      " 23  Real_GDP                           4085 non-null   float64\n",
      " 24  Yield_Curve_Spread                 4085 non-null   float64\n",
      " 25  Industrial_Production              4085 non-null   float64\n",
      " 26  M2_Money_Supply                    4085 non-null   float64\n",
      " 27  Personal_Consumption_Expenditures  4085 non-null   float64\n",
      " 28  Recession_Probability              4085 non-null   float64\n",
      " 29  GDP_Current_USD                    4085 non-null   float64\n",
      " 30  Inflation_Annual_Pct               4085 non-null   float64\n",
      " 31  Unemployment_Total_Pct             4085 non-null   float64\n",
      " 32  Exports_GDP_Pct                    4085 non-null   float64\n",
      " 33  Imports_GDP_Pct                    4085 non-null   float64\n",
      " 34  Public_Debt_GDP_Pct                4085 non-null   float64\n",
      " 35  OECD_CPI_2015idx_USA               4085 non-null   float64\n",
      " 36  OECD_Unemp_rate_pct_USA            4085 non-null   float64\n",
      " 37  Return                             4085 non-null   float64\n",
      " 38  Volatility_20d                     4085 non-null   float64\n",
      " 39  MA20                               4085 non-null   float64\n",
      " 40  MA50                               4085 non-null   float64\n",
      " 41  Momentum                           4085 non-null   float64\n",
      " 42  RSI                                4085 non-null   float64\n",
      " 43  Direction                          4085 non-null   int64  \n",
      "dtypes: float64(43), int64(1)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "              S&P500    NASDAQ  DowJones     CAC40       DAX   FTSE100  \\\n",
      "Date                                                                     \n",
      "2010-03-15 -0.002354 -0.249295  0.138139 -0.853390 -0.663445 -0.662621   \n",
      "2010-03-16  0.772371  0.520087  0.417374  1.083811  0.986356  0.511981   \n",
      "2010-03-17  0.565397  0.346427  0.456212  0.408914  0.762580  0.463197   \n",
      "2010-03-18 -0.084621  0.026133  0.430964 -0.467414 -0.215216 -0.063634   \n",
      "2010-03-19 -0.587992 -0.656045 -0.436471 -0.311194 -0.482511  0.126688   \n",
      "2010-03-22  0.488592  0.704199  0.413887  0.036817  0.038773 -0.135628   \n",
      "2010-03-23  0.708067  0.656489  1.029438  0.537982  0.408377  0.559257   \n",
      "2010-03-24 -0.631011 -0.636233 -0.593038 -0.083634  0.286439  0.062100   \n",
      "2010-03-25 -0.230361 -0.100477  0.005423  1.126937  1.356920  0.967985   \n",
      "2010-03-26  0.027837 -0.133698  0.047967 -0.280054 -0.225659 -0.511101   \n",
      "\n",
      "            Nikkei225  HangSeng  MSCIWorld     US10Y  ...  \\\n",
      "Date                                                  ...   \n",
      "2010-03-15  -0.033282 -0.533628  -0.049806 -0.084014  ...   \n",
      "2010-03-16  -0.278832 -0.237964  -0.049806 -0.617845  ...   \n",
      "2010-03-17   0.956352  1.442506  -0.049806 -0.145254  ...   \n",
      "2010-03-18  -0.847543 -0.225449  -0.049806  0.348903  ...   \n",
      "2010-03-19   0.600798  0.146724  -0.049806  0.166492  ...   \n",
      "2010-03-22  -0.436971 -1.744771  -0.049806 -0.298927  ...   \n",
      "2010-03-23  -0.038993  0.207861  -0.049806  0.190918  ...   \n",
      "2010-03-24   0.284240  0.071484  -0.049806  1.765760  ...   \n",
      "2010-03-25   0.069862 -0.939017  -0.049806  0.813106  ...   \n",
      "2010-03-26   1.278883  1.105379  -0.049806 -0.530993  ...   \n",
      "\n",
      "            Public_Debt_GDP_Pct  OECD_CPI_2015idx_USA  \\\n",
      "Date                                                    \n",
      "2010-03-15            -1.619851             -1.297184   \n",
      "2010-03-16            -1.619851             -1.297184   \n",
      "2010-03-17            -1.619851             -1.297184   \n",
      "2010-03-18            -1.619851             -1.297184   \n",
      "2010-03-19            -1.619851             -1.297184   \n",
      "2010-03-22            -1.619851             -1.297184   \n",
      "2010-03-23            -1.619851             -1.297184   \n",
      "2010-03-24            -1.619851             -1.297184   \n",
      "2010-03-25            -1.619851             -1.297184   \n",
      "2010-03-26            -1.619851             -1.297184   \n",
      "\n",
      "            OECD_Unemp_rate_pct_USA    Return  Volatility_20d      MA20  \\\n",
      "Date                                                                      \n",
      "2010-03-15                 1.918955 -0.829170       -0.490003  1.062391   \n",
      "2010-03-16                 1.918955  0.106311       -0.496255  1.100507   \n",
      "2010-03-17                 1.918955 -0.156974       -0.510047  1.138399   \n",
      "2010-03-18                 1.918955  0.083697       -0.511006  1.145228   \n",
      "2010-03-19                 1.918955 -0.735215       -0.472313  1.082649   \n",
      "2010-03-22                 1.918955  0.641269       -0.504191  1.326687   \n",
      "2010-03-23                 1.918955  0.943388       -0.658225  1.785859   \n",
      "2010-03-24                 1.918955  0.212872       -0.699716  1.592190   \n",
      "2010-03-25                 1.918955 -0.808970       -0.585290  1.332916   \n",
      "2010-03-26                 1.918955  1.112157       -0.547283  1.413779   \n",
      "\n",
      "                MA50  Momentum       RSI  Direction  \n",
      "Date                                                 \n",
      "2010-03-15 -0.005455 -3.460609  0.255147          1  \n",
      "2010-03-16  0.003306  0.021673 -0.804701          0  \n",
      "2010-03-17  0.130315 -0.034194 -0.424176          1  \n",
      "2010-03-18  0.167383  0.131847 -0.569692          0  \n",
      "2010-03-19  0.014902 -0.372762 -1.740103          1  \n",
      "2010-03-22  0.191476 -0.159419  0.691178          1  \n",
      "2010-03-23  0.432869  0.989091  0.785894          1  \n",
      "2010-03-24  0.347679 -0.510682 -0.082698          0  \n",
      "2010-03-25  0.294302 -0.848614 -2.579550          1  \n",
      "2010-03-26  0.606308 -0.299522  1.123333          1  \n",
      "\n",
      "[10 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894ecffa-e5a2-4d44-a846-caf52d7ed512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Features Selected via ANOVA F-test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>ANOVA_F_score</th>\n",
       "      <th>p_value</th>\n",
       "      <th>Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HangSeng</td>\n",
       "      <td>5.803928</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LQD</td>\n",
       "      <td>5.460275</td>\n",
       "      <td>0.019502</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US10Y</td>\n",
       "      <td>4.374051</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BND</td>\n",
       "      <td>3.515548</td>\n",
       "      <td>0.060867</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MA20</td>\n",
       "      <td>2.481190</td>\n",
       "      <td>0.115293</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IEF</td>\n",
       "      <td>2.432470</td>\n",
       "      <td>0.118923</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TLT</td>\n",
       "      <td>1.743286</td>\n",
       "      <td>0.186797</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Imports_GDP_Pct</td>\n",
       "      <td>1.692749</td>\n",
       "      <td>0.193312</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nikkei225</td>\n",
       "      <td>1.439436</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Exports_GDP_Pct</td>\n",
       "      <td>1.174765</td>\n",
       "      <td>0.278488</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Recession_Probability</td>\n",
       "      <td>1.143661</td>\n",
       "      <td>0.284943</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Inflation_Annual_Pct</td>\n",
       "      <td>0.942425</td>\n",
       "      <td>0.331712</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Volatility_20d</td>\n",
       "      <td>0.786804</td>\n",
       "      <td>0.375120</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fed_Funds_Rate</td>\n",
       "      <td>0.771583</td>\n",
       "      <td>0.379779</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Yield_Curve_Spread</td>\n",
       "      <td>0.639234</td>\n",
       "      <td>0.424035</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OECD_Unemp_rate_pct_USA</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.446888</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Meta</td>\n",
       "      <td>0.554049</td>\n",
       "      <td>0.456711</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unemployment_Rate</td>\n",
       "      <td>0.553024</td>\n",
       "      <td>0.457128</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSCIWorld</td>\n",
       "      <td>0.544080</td>\n",
       "      <td>0.460789</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Google</td>\n",
       "      <td>0.543342</td>\n",
       "      <td>0.461093</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  ANOVA_F_score   p_value  Selected\n",
       "7                  HangSeng       5.803928  0.016034      True\n",
       "14                      LQD       5.460275  0.019502      True\n",
       "9                     US10Y       4.374051  0.036552      True\n",
       "13                      BND       3.515548  0.060867      True\n",
       "39                     MA20       2.481190  0.115293      True\n",
       "12                      IEF       2.432470  0.118923      True\n",
       "11                      TLT       1.743286  0.186797      True\n",
       "33          Imports_GDP_Pct       1.692749  0.193312      True\n",
       "6                 Nikkei225       1.439436  0.230300      True\n",
       "32          Exports_GDP_Pct       1.174765  0.278488      True\n",
       "28    Recession_Probability       1.143661  0.284943      True\n",
       "30     Inflation_Annual_Pct       0.942425  0.331712      True\n",
       "38           Volatility_20d       0.786804  0.375120      True\n",
       "22           Fed_Funds_Rate       0.771583  0.379779      True\n",
       "24       Yield_Curve_Spread       0.639234  0.424035      True\n",
       "36  OECD_Unemp_rate_pct_USA       0.578645  0.446888      True\n",
       "19                     Meta       0.554049  0.456711      True\n",
       "21        Unemployment_Rate       0.553024  0.457128      True\n",
       "8                 MSCIWorld       0.544080  0.460789      True\n",
       "17                   Google       0.543342  0.461093      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature set shape: (4085, 20)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 4) FEATURE SELECTION — SelectKBest (ANOVA F-test)\n",
    "# ===============================================================\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Ensure 'Direction' is the target\n",
    "# ---------------------------------------------------------------\n",
    "target = data[\"Direction\"]\n",
    "features = data.drop(columns=[\"Direction\"])\n",
    "\n",
    "# Optional cleaning\n",
    "features = features.replace([np.inf, -np.inf], np.nan).fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Scaling (ANOVA expects standardized features)\n",
    "# ---------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Apply SelectKBest (ANOVA F-test) — Keep Top 20 variables\n",
    "# ---------------------------------------------------------------\n",
    "k = 20\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "selector.fit(X_scaled, target)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Build ranking table\n",
    "# ---------------------------------------------------------------\n",
    "scores = selector.scores_\n",
    "pvalues = selector.pvalues_\n",
    "feature_names = features.columns\n",
    "\n",
    "ranking_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"ANOVA_F_score\": scores,\n",
    "    \"p_value\": pvalues,\n",
    "    \"Selected\": selector.get_support()\n",
    "})\n",
    "\n",
    "ranking_df = ranking_df.sort_values(by=\"ANOVA_F_score\", ascending=False)\n",
    "\n",
    "print(\"Top 20 Features Selected via ANOVA F-test:\")\n",
    "display(ranking_df.head(k))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5) Filter dataset to keep only the selected features\n",
    "# ---------------------------------------------------------------\n",
    "selected_features = feature_names[selector.get_support()]\n",
    "X_selected = features[selected_features]\n",
    "\n",
    "print(\"Selected feature set shape:\", X_selected.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d240312f-b774-4725-ab30-564a922b65f3",
   "metadata": {},
   "source": [
    "This step applies ANOVA F-test–based feature selection to identify the variables that have the strongest statistical relationship with the binary target Direction.\n",
    "All features are first standardized, as ANOVA assumes comparable scales and benefits from normalized inputs.\n",
    "\n",
    "The results show the top 20 features ranked by their F-scores.\n",
    "Although most F-scores remain relatively small—consistent with the weak linear relationships observed earlier—some variables exhibit slightly stronger discriminatory power.\n",
    "Among them, HangSeng, LQD, US10Y, BND, and MA20 appear as the most informative features under this test.\n",
    "\n",
    "The selected feature set contains 20 variables, providing a reduced-dimension representation that may help improve model efficiency and reduce overfitting.\n",
    "However, given the low F-scores and modest significance levels, these results confirm that daily direction prediction remains a low-signal problem where no single feature dominates, and performance will likely rely on multivariate interactions captured by machine-learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0ba745-f5fd-46b4-9b68-d657519e8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4085 entries, 2010-03-15 to 2025-11-26\n",
      "Data columns (total 44 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   S&P500                             4085 non-null   float64\n",
      " 1   NASDAQ                             4085 non-null   float64\n",
      " 2   DowJones                           4085 non-null   float64\n",
      " 3   CAC40                              4085 non-null   float64\n",
      " 4   DAX                                4085 non-null   float64\n",
      " 5   FTSE100                            4085 non-null   float64\n",
      " 6   Nikkei225                          4085 non-null   float64\n",
      " 7   HangSeng                           4085 non-null   float64\n",
      " 8   MSCIWorld                          4085 non-null   float64\n",
      " 9   US10Y                              4085 non-null   float64\n",
      " 10  US2Y                               4085 non-null   float64\n",
      " 11  TLT                                4085 non-null   float64\n",
      " 12  IEF                                4085 non-null   float64\n",
      " 13  BND                                4085 non-null   float64\n",
      " 14  LQD                                4085 non-null   float64\n",
      " 15  Apple                              4085 non-null   float64\n",
      " 16  Microsoft                          4085 non-null   float64\n",
      " 17  Google                             4085 non-null   float64\n",
      " 18  Amazon                             4085 non-null   float64\n",
      " 19  Meta                               4085 non-null   float64\n",
      " 20  Inflation_CPI                      4085 non-null   float64\n",
      " 21  Unemployment_Rate                  4085 non-null   float64\n",
      " 22  Fed_Funds_Rate                     4085 non-null   float64\n",
      " 23  Real_GDP                           4085 non-null   float64\n",
      " 24  Yield_Curve_Spread                 4085 non-null   float64\n",
      " 25  Industrial_Production              4085 non-null   float64\n",
      " 26  M2_Money_Supply                    4085 non-null   float64\n",
      " 27  Personal_Consumption_Expenditures  4085 non-null   float64\n",
      " 28  Recession_Probability              4085 non-null   float64\n",
      " 29  GDP_Current_USD                    4085 non-null   float64\n",
      " 30  Inflation_Annual_Pct               4085 non-null   float64\n",
      " 31  Unemployment_Total_Pct             4085 non-null   float64\n",
      " 32  Exports_GDP_Pct                    4085 non-null   float64\n",
      " 33  Imports_GDP_Pct                    4085 non-null   float64\n",
      " 34  Public_Debt_GDP_Pct                4085 non-null   float64\n",
      " 35  OECD_CPI_2015idx_USA               4085 non-null   float64\n",
      " 36  OECD_Unemp_rate_pct_USA            4085 non-null   float64\n",
      " 37  Return                             4085 non-null   float64\n",
      " 38  Volatility_20d                     4085 non-null   float64\n",
      " 39  MA20                               4085 non-null   float64\n",
      " 40  MA50                               4085 non-null   float64\n",
      " 41  Momentum                           4085 non-null   float64\n",
      " 42  RSI                                4085 non-null   float64\n",
      " 43  Direction                          4085 non-null   int64  \n",
      "dtypes: float64(43), int64(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41c9679b-eb65-4c17-9cac-0e35bb742a44",
   "metadata": {},
   "source": [
    "The data.info() output confirms that the final dataset contains 4,085 daily observations spanning from 2010-03-15 to 2025-11-26.\n",
    "A total of 44 columns are present, consisting of:\n",
    "\n",
    "43 numeric float features (market indices, bond yields/ETFs, company returns, macroeconomic indicators, and engineered technical signals)\n",
    "1 integer column (Direction), which serves as the binary classification target.\n",
    "All features show 4085 non-null values, meaning there are no missing entries after the cleaning and preprocessing stages.\n",
    "The DatetimeIndex ensures proper temporal alignment, which is essential for time-series modeling and walk-forward validation.\n",
    "\n",
    "Overall, the dataset is clean, complete, and structurally consistent, ready for feature selection, model training, and predictive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edba53ff-9cf4-4091-a74b-63a93ee1cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape: (4085, 23)\n",
      "Columns kept: ['HangSeng', 'LQD', 'US10Y', 'BND', 'MA20', 'IEF', 'TLT', 'Imports_GDP_Pct', 'Nikkei225', 'Exports_GDP_Pct', 'Recession_Probability', 'Inflation_Annual_Pct', 'Volatility_20d', 'Fed_Funds_Rate', 'Yield_Curve_Spread', 'OECD_Unemp_rate_pct_USA', 'Meta', 'Unemployment_Rate', 'MSCIWorld', 'Google', 'Apple', 'Return', 'Direction']\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# STEP — REDUCE DATASET TO TOP 20 FEATURES + REQUIRED COLUMNS\n",
    "# ===============================================================\n",
    "\n",
    "# Top 20 selected features\n",
    "\n",
    "top20_features = [\n",
    "    \"HangSeng\",\n",
    "    \"LQD\",\n",
    "    \"US10Y\",\n",
    "    \"BND\",\n",
    "    \"MA20\",\n",
    "    \"IEF\",\n",
    "    \"TLT\",\n",
    "    \"Imports_GDP_Pct\",\n",
    "    \"Nikkei225\",\n",
    "    \"Exports_GDP_Pct\",\n",
    "    \"Recession_Probability\",\n",
    "    \"Inflation_Annual_Pct\",\n",
    "    \"Volatility_20d\",\n",
    "    \"Fed_Funds_Rate\",\n",
    "    \"Yield_Curve_Spread\",\n",
    "    \"OECD_Unemp_rate_pct_USA\",\n",
    "    \"Meta\",\n",
    "    \"Unemployment_Rate\",\n",
    "    \"MSCIWorld\",\n",
    "    \"Google\"\n",
    "]\n",
    "\n",
    "mandatory_columns = [\"Apple\", \"Return\", \"Direction\"]\n",
    "\n",
    "for col in mandatory_columns:\n",
    "    if col not in data.columns:\n",
    "        print(f\"Warning: column '{col}' was not found in data.\")\n",
    "\n",
    "keep_columns = top20_features + mandatory_columns\n",
    "data = data[keep_columns].copy()\n",
    "\n",
    "print(\"New dataset shape:\", data.shape)\n",
    "print(\"Columns kept:\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e4e0cf7-f359-440e-a5eb-4a94442d0be5",
   "metadata": {},
   "source": [
    "This step reduces the dataset to the top 20 features previously selected through ANOVA F-test, combined with mandatory columns required for modeling (Apple, Return, and Direction).\n",
    "\n",
    "A defensive check ensures that all mandatory columns exist in the dataset before subsetting.\n",
    "The selected feature list includes a mix of:\n",
    "\n",
    "Market indices (e.g., HangSeng, Nikkei225, MSCIWorld)\n",
    "Bond ETFs and yields (e.g., LQD, US10Y, IEF, TLT, BND)\n",
    "Macroeconomic indicators (e.g., Unemployment_Rate, Inflation_Annual_Pct, OECD_Unemp_rate_pct_USA)\n",
    "Technical indicators (e.g., MA20, Volatility_20d, Yield_Curve_Spread)\n",
    "Company-specific variables (Meta, Google)\n",
    "Finally, the dataset is trimmed to include only the selected columns, which reduces dimensionality, improves model efficiency, and minimizes noise.\n",
    "\n",
    "The resulting dataset shape indicates that all required variables have been successfully retained and the feature space is now well-structured for supervised learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25c2e7b-8507-4796-89ea-ddf389546764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4085 entries, 2010-03-15 to 2025-11-26\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   HangSeng                 4085 non-null   float64\n",
      " 1   LQD                      4085 non-null   float64\n",
      " 2   US10Y                    4085 non-null   float64\n",
      " 3   BND                      4085 non-null   float64\n",
      " 4   MA20                     4085 non-null   float64\n",
      " 5   IEF                      4085 non-null   float64\n",
      " 6   TLT                      4085 non-null   float64\n",
      " 7   Imports_GDP_Pct          4085 non-null   float64\n",
      " 8   Nikkei225                4085 non-null   float64\n",
      " 9   Exports_GDP_Pct          4085 non-null   float64\n",
      " 10  Recession_Probability    4085 non-null   float64\n",
      " 11  Inflation_Annual_Pct     4085 non-null   float64\n",
      " 12  Volatility_20d           4085 non-null   float64\n",
      " 13  Fed_Funds_Rate           4085 non-null   float64\n",
      " 14  Yield_Curve_Spread       4085 non-null   float64\n",
      " 15  OECD_Unemp_rate_pct_USA  4085 non-null   float64\n",
      " 16  Meta                     4085 non-null   float64\n",
      " 17  Unemployment_Rate        4085 non-null   float64\n",
      " 18  MSCIWorld                4085 non-null   float64\n",
      " 19  Google                   4085 non-null   float64\n",
      " 20  Apple                    4085 non-null   float64\n",
      " 21  Return                   4085 non-null   float64\n",
      " 22  Direction                4085 non-null   int64  \n",
      "dtypes: float64(22), int64(1)\n",
      "memory usage: 765.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75133b2-8f6f-4817-bfd8-44acc03a0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(OUT / \"Cleaned_Features_for_ML_20ANOVA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0661038f-8fd0-44cb-9fde-c4fbd5f5a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3268, 20) | Test shape: (817, 20)\n",
      "[INFO] Saved model results for: LR\n",
      "[INFO] Saved model results for: KNN\n",
      "[INFO] Saved model results for: CART\n",
      "[INFO] Saved model results for: SVC\n",
      "[INFO] Saved model results for: MLP\n",
      "[INFO] Saved model results for: ABR\n",
      "[INFO] Saved model results for: GBR\n",
      "[INFO] Saved model results for: RFR\n",
      "[INFO] Saved model results for: ETR\n",
      "[INFO] Saved JSON to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.json\n",
      "[INFO] Saved CSV to: C:\\Users\\dax_a\\Documents\\GitHub\\ESILV-MLproject-AU-BEJOT\\data\\model_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2a22c_row0_col1 {\n",
       "  background-color: #5da5d1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row0_col2 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row0_col3, #T_2a22c_row1_col2, #T_2a22c_row1_col4, #T_2a22c_row2_col1, #T_2a22c_row7_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row0_col4 {\n",
       "  background-color: #083b7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row0_col5 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row1_col1 {\n",
       "  background-color: #4191c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row1_col3 {\n",
       "  background-color: #083573;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row1_col5 {\n",
       "  background-color: #b4d3e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row2_col2 {\n",
       "  background-color: #125da6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row2_col3 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row2_col4 {\n",
       "  background-color: #2979b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row2_col5 {\n",
       "  background-color: #d8e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row3_col1, #T_2a22c_row5_col1 {\n",
       "  background-color: #3c8cc3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row3_col2 {\n",
       "  background-color: #08316d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row3_col3 {\n",
       "  background-color: #3080bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row3_col4 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row3_col5 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row4_col1 {\n",
       "  background-color: #4f9bcb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row4_col2 {\n",
       "  background-color: #2373b6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row4_col3 {\n",
       "  background-color: #3282be;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row4_col4 {\n",
       "  background-color: #3888c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row4_col5 {\n",
       "  background-color: #8dc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row5_col2 {\n",
       "  background-color: #0c56a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row5_col3 {\n",
       "  background-color: #58a1cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row5_col4 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row5_col5 {\n",
       "  background-color: #539ecd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row6_col1, #T_2a22c_row8_col2, #T_2a22c_row8_col3, #T_2a22c_row8_col4, #T_2a22c_row8_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row6_col2 {\n",
       "  background-color: #cde0f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row6_col3, #T_2a22c_row7_col3 {\n",
       "  background-color: #d5e5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row6_col4 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row6_col5 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row7_col1 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row7_col2 {\n",
       "  background-color: #5ba3d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a22c_row7_col4 {\n",
       "  background-color: #77b5d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a22c_row8_col1 {\n",
       "  background-color: #f3f8fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2a22c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2a22c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2a22c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2a22c_level0_col2\" class=\"col_heading level0 col2\" >F1-score</th>\n",
       "      <th id=\"T_2a22c_level0_col3\" class=\"col_heading level0 col3\" >AUC</th>\n",
       "      <th id=\"T_2a22c_level0_col4\" class=\"col_heading level0 col4\" >F2-score</th>\n",
       "      <th id=\"T_2a22c_level0_col5\" class=\"col_heading level0 col5\" >Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2a22c_row0_col0\" class=\"data row0 col0\" >LR</td>\n",
       "      <td id=\"T_2a22c_row0_col1\" class=\"data row0 col1\" >0.517748</td>\n",
       "      <td id=\"T_2a22c_row0_col2\" class=\"data row0 col2\" >0.677049</td>\n",
       "      <td id=\"T_2a22c_row0_col3\" class=\"data row0 col3\" >0.519240</td>\n",
       "      <td id=\"T_2a22c_row0_col4\" class=\"data row0 col4\" >0.825670</td>\n",
       "      <td id=\"T_2a22c_row0_col5\" class=\"data row0 col5\" >0.131266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2a22c_row1_col0\" class=\"data row1 col0\" >SVC</td>\n",
       "      <td id=\"T_2a22c_row1_col1\" class=\"data row1 col1\" >0.522644</td>\n",
       "      <td id=\"T_2a22c_row1_col2\" class=\"data row1 col2\" >0.686495</td>\n",
       "      <td id=\"T_2a22c_row1_col3\" class=\"data row1 col3\" >0.518315</td>\n",
       "      <td id=\"T_2a22c_row1_col4\" class=\"data row1 col4\" >0.845545</td>\n",
       "      <td id=\"T_2a22c_row1_col5\" class=\"data row1 col5\" >2.366060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2a22c_row2_col0\" class=\"data row2 col0\" >ETR</td>\n",
       "      <td id=\"T_2a22c_row2_col1\" class=\"data row2 col1\" >0.544676</td>\n",
       "      <td id=\"T_2a22c_row2_col2\" class=\"data row2 col2\" >0.645038</td>\n",
       "      <td id=\"T_2a22c_row2_col3\" class=\"data row2 col3\" >0.516339</td>\n",
       "      <td id=\"T_2a22c_row2_col4\" class=\"data row2 col4\" >0.725633</td>\n",
       "      <td id=\"T_2a22c_row2_col5\" class=\"data row2 col5\" >1.220021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2a22c_row3_col0\" class=\"data row3 col0\" >ABR</td>\n",
       "      <td id=\"T_2a22c_row3_col1\" class=\"data row3 col1\" >0.523868</td>\n",
       "      <td id=\"T_2a22c_row3_col2\" class=\"data row3 col2\" >0.685020</td>\n",
       "      <td id=\"T_2a22c_row3_col3\" class=\"data row3 col3\" >0.506533</td>\n",
       "      <td id=\"T_2a22c_row3_col4\" class=\"data row3 col4\" >0.840620</td>\n",
       "      <td id=\"T_2a22c_row3_col5\" class=\"data row3 col5\" >1.963307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2a22c_row4_col0\" class=\"data row4 col0\" >RFR</td>\n",
       "      <td id=\"T_2a22c_row4_col1\" class=\"data row4 col1\" >0.520196</td>\n",
       "      <td id=\"T_2a22c_row4_col2\" class=\"data row4 col2\" >0.624521</td>\n",
       "      <td id=\"T_2a22c_row4_col3\" class=\"data row4 col3\" >0.506230</td>\n",
       "      <td id=\"T_2a22c_row4_col4\" class=\"data row4 col4\" >0.701075</td>\n",
       "      <td id=\"T_2a22c_row4_col5\" class=\"data row4 col5\" >3.199183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2a22c_row5_col0\" class=\"data row5 col0\" >GBR</td>\n",
       "      <td id=\"T_2a22c_row5_col1\" class=\"data row5 col1\" >0.523868</td>\n",
       "      <td id=\"T_2a22c_row5_col2\" class=\"data row5 col2\" >0.651121</td>\n",
       "      <td id=\"T_2a22c_row5_col3\" class=\"data row5 col3\" >0.500937</td>\n",
       "      <td id=\"T_2a22c_row5_col4\" class=\"data row5 col4\" >0.757513</td>\n",
       "      <td id=\"T_2a22c_row5_col5\" class=\"data row5 col5\" >4.369032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2a22c_row6_col0\" class=\"data row6 col0\" >CART</td>\n",
       "      <td id=\"T_2a22c_row6_col1\" class=\"data row6 col1\" >0.485924</td>\n",
       "      <td id=\"T_2a22c_row6_col2\" class=\"data row6 col2\" >0.498807</td>\n",
       "      <td id=\"T_2a22c_row6_col3\" class=\"data row6 col3\" >0.485111</td>\n",
       "      <td id=\"T_2a22c_row6_col4\" class=\"data row6 col4\" >0.493157</td>\n",
       "      <td id=\"T_2a22c_row6_col5\" class=\"data row6 col5\" >0.040912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2a22c_row7_col0\" class=\"data row7 col0\" >MLP</td>\n",
       "      <td id=\"T_2a22c_row7_col1\" class=\"data row7 col1\" >0.506732</td>\n",
       "      <td id=\"T_2a22c_row7_col2\" class=\"data row7 col2\" >0.578892</td>\n",
       "      <td id=\"T_2a22c_row7_col3\" class=\"data row7 col3\" >0.485012</td>\n",
       "      <td id=\"T_2a22c_row7_col4\" class=\"data row7 col4\" >0.618856</td>\n",
       "      <td id=\"T_2a22c_row7_col5\" class=\"data row7 col5\" >7.647316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a22c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_2a22c_row8_col0\" class=\"data row8 col0\" >KNN</td>\n",
       "      <td id=\"T_2a22c_row8_col1\" class=\"data row8 col1\" >0.487148</td>\n",
       "      <td id=\"T_2a22c_row8_col2\" class=\"data row8 col2\" >0.447958</td>\n",
       "      <td id=\"T_2a22c_row8_col3\" class=\"data row8 col3\" >0.477845</td>\n",
       "      <td id=\"T_2a22c_row8_col4\" class=\"data row8 col4\" >0.416667</td>\n",
       "      <td id=\"T_2a22c_row8_col5\" class=\"data row8 col5\" >0.010747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a5f5968230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# IMPORTS\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, GradientBoostingClassifier,\n",
    "    RandomForestClassifier, ExtraTreesClassifier\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, fbeta_score\n",
    ")\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# FROM YOUR RESULTS MANAGER\n",
    "# ===============================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "OUT = Path(\"../data\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "def make_json_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [make_json_serializable(i) for i in obj]\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.integer, np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def save_results_to_json(results_dict, filename=\"model_results.json\"):\n",
    "    filepath = OUT / filename\n",
    "    serializable = make_json_serializable(results_dict)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(serializable, f, indent=4)\n",
    "    print(f\"[INFO] Saved JSON to: {filepath.resolve()}\")\n",
    "\n",
    "\n",
    "def save_results_to_csv(results_dict, filename=\"model_results.csv\"):\n",
    "    rows = []\n",
    "\n",
    "    for model_name, res in results_dict.items():\n",
    "        cm = np.array(res.get(\"confusion_matrix\", np.zeros((2, 2))))\n",
    "        cr = res.get(\"classification_report\", {})\n",
    "        roc_auc = res.get(\"roc_auc\")\n",
    "        f2 = res.get(\"f2_score\")\n",
    "        comp_time = res.get(\"computation_time_sec\")\n",
    "        dataset_label = res.get(\"dataset_label\", \"Unknown\")\n",
    "\n",
    "        accuracy = cr.get(\"accuracy\")\n",
    "\n",
    "        # Detect positive class\n",
    "        pos_key = \"1\" if \"1\" in cr else None\n",
    "        if not pos_key:\n",
    "            numeric_keys = [k for k in cr.keys() if k.isdigit()]\n",
    "            pos_key = numeric_keys[-1] if numeric_keys else None\n",
    "\n",
    "        precision = recall = f1_class1 = None\n",
    "        if pos_key and isinstance(cr.get(pos_key), dict):\n",
    "            precision = cr[pos_key].get(\"precision\")\n",
    "            recall = cr[pos_key].get(\"recall\")\n",
    "            f1_class1 = cr[pos_key].get(\"f1-score\")\n",
    "\n",
    "        # Confusion matrix split\n",
    "        tn = fp = fn = tp = None\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        rows.append({\n",
    "            \"Dataset\": dataset_label,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision (class 1)\": precision,\n",
    "            \"Recall (class 1)\": recall,\n",
    "            \"F1-score (class 1)\": f1_class1,\n",
    "            \"F2-score\": f2,\n",
    "            \"ROC-AUC\": roc_auc,\n",
    "            \"Computation Time (sec)\": comp_time,\n",
    "            \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    filepath = OUT / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"[INFO] Saved CSV to: {filepath.resolve()}\")\n",
    "\n",
    "\n",
    "def save_results(model_name, y_true, y_pred, y_prob=None, comp_time=None, dataset_label=\"Unknown\"):\n",
    "    results[model_name] = {}\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    results[model_name][\"confusion_matrix\"] = cm\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    results[model_name][\"classification_report\"] = report\n",
    "\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            results[model_name][\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
    "        except:\n",
    "            results[model_name][\"roc_auc\"] = None\n",
    "\n",
    "    results[model_name][\"f2_score\"] = fbeta_score(y_true, y_pred, beta=2)\n",
    "    results[model_name][\"computation_time_sec\"] = comp_time\n",
    "    results[model_name][\"dataset_label\"] = dataset_label\n",
    "\n",
    "    print(f\"[INFO] Saved model results for: {model_name}\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# TRAIN / TEST SPLIT\n",
    "# ===============================================================\n",
    "features = data.drop(columns=['Apple', 'Return', 'Direction'])\n",
    "target = data[\"Direction\"]\n",
    "\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape} | Test shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# FEATURE TYPES\n",
    "# ===============================================================\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# PREPROCESSING PIPELINES\n",
    "# ===============================================================\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# DEFINE MODELS\n",
    "# ===============================================================\n",
    "models = [\n",
    "    ('LR',  LogisticRegression(max_iter=5000, random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('CART', DecisionTreeClassifier(max_depth=6, random_state=42)),\n",
    "    ('SVC', SVC(kernel='rbf', probability=True, random_state=42)),\n",
    "    ('MLP', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=5000, random_state=42)),\n",
    "    ('ABR', AdaBoostClassifier(n_estimators=300, random_state=42)),\n",
    "    ('GBR', GradientBoostingClassifier(n_estimators=300, random_state=42)),\n",
    "    ('RFR', RandomForestClassifier(n_estimators=300, random_state=42)),\n",
    "    ('ETR', ExtraTreesClassifier(n_estimators=300, random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# MODEL LOOP + SAVE RESULTS\n",
    "# ===============================================================\n",
    "rows_for_display = []\n",
    "DATASET_LABEL = \"APPLE_DIRECTION_8D\"   # or dynamic\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "\n",
    "    t0 = time()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    comp_time = time() - t0\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    # === Use the unified save_results() function ===\n",
    "    save_results(\n",
    "        model_name=name,\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        y_prob=y_prob,\n",
    "        comp_time=comp_time,\n",
    "        dataset_label=DATASET_LABEL\n",
    "    )\n",
    "\n",
    "    # Row for view in notebook\n",
    "    rows_for_display.append([\n",
    "        name,\n",
    "        accuracy_score(y_test, y_pred),\n",
    "        f1_score(y_test, y_pred),\n",
    "        roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        fbeta_score(y_test, y_pred, beta=2),\n",
    "        comp_time\n",
    "    ])\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# EXPORT JSON + CSV FOR DASHBOARD\n",
    "# ===============================================================\n",
    "save_results_to_json(results)\n",
    "save_results_to_csv(results)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# FINAL SUMMARY TABLE\n",
    "# ===============================================================\n",
    "df_results = pd.DataFrame(\n",
    "    rows_for_display,\n",
    "    columns=[\"Model\", \"Accuracy\", \"F1-score\", \"AUC\", \"F2-score\", \"Time (sec)\"]\n",
    ").sort_values(\"AUC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(df_results.style.background_gradient(cmap=\"Blues\"))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2a41f59-b0aa-4f3e-98a9-5c509e3154d3",
   "metadata": {},
   "source": [
    "Binary Classification – Pipeline Summary\n",
    "This block builds a full ML pipeline to predict the binary target Direction.\n",
    "The process includes:\n",
    "\n",
    "Train/Test split (time-ordered) to avoid data leakage.\n",
    "Automatic preprocessing: median imputation + RobustScaler for numeric data, OneHotEncoding for categorical data.\n",
    "Model comparison using 5-fold cross-validated ROC-AUC.\n",
    "Training and evaluation on multiple algorithms (LR, KNN, CART, SVC, MLP, ABR, GBR, RFR, ETR).\n",
    "Final metrics reported: CV AUC, Train Accuracy, Test Accuracy, Test AUC, and F1-score.\n",
    "This step identifies the best-performing model and highlights potential overfitting vs. generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643ee39-dae1-4170-8188-30700db2edef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
